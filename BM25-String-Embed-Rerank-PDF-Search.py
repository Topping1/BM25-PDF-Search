import osimport reimport sysimport jsonimport subprocessimport numpy as npfrom PyQt5.QtWidgets import (    QApplication,    QMainWindow,    QWidget,    QVBoxLayout,    QHBoxLayout,    QLabel,    QLineEdit,    QTextEdit,    QPushButton,    QGraphicsView,    QGraphicsScene,    QGraphicsPixmapItem,    QGraphicsRectItem,    QStatusBar,    QComboBox,)from PyQt5.QtGui import QPixmap, QFont, QColor, QKeySequencefrom PyQt5.QtCore import Qt, QRectFfrom PyQt5.QtWidgets import QShortcut, QScrollBarimport fitz  # PyMuPDFimport unicodedata# --- BM25s imports ---import bm25s################################################################################ Attempt fastembed import###############################################################################FASTEMBED_AVAILABLE = FalseFASTEMBED_ENCODER = Nonetry:    from fastembed import TextEmbedding    FASTEMBED_AVAILABLE = Trueexcept ImportError:    TextEmbedding = None################################################################################ Global variables for corpus and BM25 model###############################################################################GLOBAL_CORPUS = []GLOBAL_BM25_MODEL = None# We'll store a fastembed.TextEmbedding model here if neededGLOBAL_EMBED_MODEL = None# The maximum number of BM25 search hits to return before any re-ranking.MAX_SEARCH_RESULTS = 50################################################################################ Functions that do not depend on the SearchApp class###############################################################################def remove_accents(input_str):    nfkd_form = unicodedata.normalize('NFD', input_str)    return ''.join([c for c in nfkd_form if not unicodedata.combining(c)])def load_corpus_and_initialize_bm25():    """    Load all .json files in the current directory into GLOBAL_CORPUS    and build a BM25 index. Also attempt to load matching .emb files    in parallel to store embeddings (if available).    """    global GLOBAL_CORPUS, GLOBAL_BM25_MODEL    # Clear out any existing data    GLOBAL_CORPUS.clear()    GLOBAL_BM25_MODEL = None    # Gather all .json files in the current directory    json_files = [f for f in os.listdir(".") if f.endswith(".json")]    if not json_files:        print("No JSON files found in the current directory.")        return    # Load data from each JSON file    for file_name in json_files:        with open(file_name, "r", encoding="utf-8") as json_file:            docs = json.load(json_file)            GLOBAL_CORPUS.extend(docs)    if not GLOBAL_CORPUS:        print("No documents found in any JSON file.")        return    # Build BM25 index as before    texts = [doc['text'] for doc in GLOBAL_CORPUS if 'text' in doc]    if texts:        # Only build a BM25 model if we actually have text        GLOBAL_BM25_MODEL = bm25s.BM25()        tokenized_corpus = bm25s.tokenize(texts, stopwords="en")        GLOBAL_BM25_MODEL.index(tokenized_corpus)        print("BM25 model successfully initialized.")    else:        print("No textual data to build BM25 model.")    # Now attempt to load .emb files    load_embeddings_for_corpus(json_files)def load_embeddings_for_corpus(json_files):    """    For each .json file in 'json_files', tries to find a matching .emb file.    If present, load the embeddings from it and match them with the same pages    in GLOBAL_CORPUS. The assumption is that the .emb file has the same length    and order of pages as the original .json.    """    global GLOBAL_CORPUS    # We'll track how many embeddings we actually found    emb_count = 0    # We'll need to map each JSON file's pages in GLOBAL_CORPUS by index    # so we can attach embeddings properly. For that, let's do an approach:    # We'll load the .emb data, then we match them to the docs that came    # from that JSON. We rely on them being in the same order (and same length).    # Alternatively, we could match by filename+page_number. But let's assume    # identical ordering in the .emb and .json.    corpus_index = 0    for file_name in json_files:        emb_file_name = f"{os.path.splitext(file_name)[0]}.emb"        if not os.path.exists(emb_file_name):            # Move the corpus_index forward by the # of pages in this JSON            # so that we line up with the correct docs in subsequent iteration            with open(file_name, "r", encoding="utf-8") as json_file:                pages_in_json = json.load(json_file)            corpus_index += len(pages_in_json)            continue        # We found an .emb file        with open(file_name, "r", encoding="utf-8") as json_file:            pages_in_json = json.load(json_file)        with open(emb_file_name, "r", encoding="utf-8") as emb_file:            pages_with_emb = json.load(emb_file)        # They should be the same length        if len(pages_in_json) != len(pages_with_emb):            print(f"Warning: mismatch in #pages for {file_name} and {emb_file_name}")            # We'll match up to the min length            min_len = min(len(pages_in_json), len(pages_with_emb))        else:            min_len = len(pages_in_json)        # Attach the embeddings to the correct docs in GLOBAL_CORPUS        for i in range(min_len):            # We'll assume the same order, so:            # doc = GLOBAL_CORPUS[corpus_index + i]            doc = GLOBAL_CORPUS[corpus_index + i]            if 'embedding' in pages_with_emb[i]:                doc['embedding'] = np.array(pages_with_emb[i]['embedding'], dtype=np.float32)                emb_count += 1        # Advance the corpus index        corpus_index += len(pages_in_json)    print(f"Loaded embeddings for {emb_count} pages total.")################################################################################ Minimal span-based scoring functions (unchanged)###############################################################################def minimal_span_score(text, query_terms):    norm_text = remove_accents(text.lower())    norm_query_terms = [remove_accents(qt.lower()) for qt in query_terms]    words = norm_text.split()    positions = {term: [] for term in norm_query_terms}    for i, w in enumerate(words):        if w in positions:            positions[w].append(i)    for term in norm_query_terms:        if not positions[term]:            return 0.0    all_positions = []    for t in norm_query_terms:        all_positions.extend((p, t) for p in positions[t])    all_positions.sort(key=lambda x: x[0])    best_span = len(words) + 1    found_terms = {}    left = 0    for right in range(len(all_positions)):        pos_right, term_right = all_positions[right]        found_terms[term_right] = pos_right        while len(found_terms) == len(norm_query_terms):            span = max(found_terms.values()) - min(found_terms.values()) + 1            if span < best_span:                best_span = span            pos_left, term_left = all_positions[left]            if found_terms.get(term_left, None) == pos_left:                del found_terms[term_left]            left += 1    return 1.0 / (best_span + 1)def rerank_minimal_span(top_docs, query_terms):    global GLOBAL_CORPUS    doc_scores = []    for doc_id, bm25_score in top_docs:        text = GLOBAL_CORPUS[doc_id]['text']        ms_score = minimal_span_score(text, query_terms)        doc_scores.append((doc_id, ms_score))    doc_scores.sort(key=lambda x: x[1], reverse=True)    return doc_scores################################################################################ Exact text search (unchanged)###############################################################################def rerank_exact_text(top_docs, query_phrase):    global GLOBAL_CORPUS    query_norm = remove_accents(query_phrase.lower())    matched = []    unmatched = []    for doc_id, bm25_score in top_docs:        doc_text = GLOBAL_CORPUS[doc_id]['text']        doc_text_norm = remove_accents(doc_text.lower())        if query_norm in doc_text_norm:            matched.append((doc_id, bm25_score))        else:            unmatched.append((doc_id, bm25_score))    return matched + unmatched################################################################################ Helper function for "Simple text search"###############################################################################def parse_simple_search_query(query_str):    pattern = r'"([^"]+)"|(\S+)'    matches = re.findall(pattern, query_str)    quoted_phrases = []    unquoted_words = []    for (phrase, word) in matches:        if phrase:            quoted_phrases.append(phrase)        elif word:            unquoted_words.append(word)    return quoted_phrases, unquoted_words################################################################################ A custom QGraphicsView to handle clicking on PDF pages (unchanged)###############################################################################class ClickableGraphicsView(QGraphicsView):    def __init__(self, parent=None):        super().__init__(parent)        self.current_pdf_path = None        self.current_page = 1        self.total_pages = 1    def set_pdf_details(self, pdf_path, page, total_pages):        self.current_pdf_path = pdf_path        self.current_page = page        self.total_pages = total_pages    def mousePressEvent(self, event):        if event.button() == Qt.LeftButton and self.current_pdf_path:            try:                subprocess.run(["okular", self.current_pdf_path, "-p", str(self.current_page)])            except Exception as e:                print(f"Failed to open PDF: {e}")        super().mousePressEvent(event)################################################################################ The main GUI application class###############################################################################class SearchApp(QMainWindow):    def __init__(self):        super().__init__()        self.setWindowTitle("Search Interface with PDF Viewer")        self.current_result_index = 0        self.results = []        self.query_terms = []        self.font_size = 12        self.scale_factor = 1.0        self.embeddings_present = False  # whether we found .emb files        self.init_ui()        # Load corpus + BM25 + embeddings        load_corpus_and_initialize_bm25()        # Check if we actually loaded any embeddings        self.embeddings_present = any(('embedding' in doc) for doc in GLOBAL_CORPUS)        # Attempt to initialize the global embedding model        # only if we have embeddings (otherwise no need).        global GLOBAL_EMBED_MODEL, FASTEMBED_AVAILABLE        if self.embeddings_present:            if FASTEMBED_AVAILABLE:                # Initialize the embedding model once                GLOBAL_EMBED_MODEL = TextEmbedding(model_name="nomic-ai/nomic-embed-text-v1")                # If we also have a BM25, let's say: "Corpus and Embeddings loaded successfully. Ready to search."                # Or if no BM25, we can adapt the message. We'll keep it simple:                if GLOBAL_BM25_MODEL is not None:                    self.result_display.setText("Corpus and Embeddings loaded successfully. Ready to search.")                else:                    self.result_display.setText("Embeddings loaded successfully (no BM25). Ready to search.")            else:                # We have .emb files, but fastembed is not installed                if GLOBAL_BM25_MODEL is not None:                    self.result_display.setText("Corpus and Embeddings loaded successfully. FastEmbed library not installed, embeddings search will not work.")                else:                    self.result_display.setText("Embeddings loaded successfully. FastEmbed library not installed, embeddings search will not work.")        else:            # No embeddings found            if GLOBAL_BM25_MODEL is None:                self.result_display.setText("No corpus or BM25 model available.")            else:                self.result_display.setText("Corpus loaded successfully. Ready to search.")    def init_ui(self):        container = QWidget()        layout = QHBoxLayout()        left_layout = QVBoxLayout()        # Row for "Search method" and "Reranking method"        top_row_layout = QHBoxLayout()        self.search_method_label = QLabel("Search method:")        self.search_method_combo = QComboBox()        self.search_method_combo.addItem("BM25")        self.search_method_combo.addItem("Simple text search")        self.search_method_combo.addItem("Embeddings search")  # NEW        self.search_method_combo.currentIndexChanged.connect(self.update_rerank_combo_status)        top_row_layout.addWidget(self.search_method_label)        top_row_layout.addWidget(self.search_method_combo)        self.rerank_label = QLabel("Reranking method:")        self.rerank_combo = QComboBox()        self.rerank_combo.addItem("No reranking")        self.rerank_combo.addItem("Minimal span-based scoring")        self.rerank_combo.addItem("Exact text search")        self.rerank_combo.addItem("Embeddings rerank")        self.rerank_combo.setEditable(False)        self.rerank_combo.currentIndexChanged.connect(self.search)        top_row_layout.addWidget(self.rerank_label)        top_row_layout.addWidget(self.rerank_combo)        left_layout.addLayout(top_row_layout)        # Search label/input        self.query_label = QLabel("Search query:")        self.query_input = QLineEdit()        self.query_input.setFont(QFont("Arial", self.font_size))        self.query_input.returnPressed.connect(self.search)        left_layout.addWidget(self.query_label)        left_layout.addWidget(self.query_input)        # Navigation buttons        button_layout = QHBoxLayout()        self.prev_button = QPushButton("<--")        self.next_button = QPushButton("-->")        self.prev_button.clicked.connect(self.show_previous_chunk)        self.next_button.clicked.connect(self.show_next_chunk)        button_layout.addWidget(self.prev_button)        button_layout.addWidget(self.next_button)        self.decrease_font_button = QPushButton("-")        self.decrease_font_button.clicked.connect(self.decrease_font_size)        button_layout.addWidget(self.decrease_font_button)        self.increase_font_button = QPushButton("+")        self.increase_font_button.clicked.connect(self.increase_font_size)        button_layout.addWidget(self.increase_font_button)        left_layout.addLayout(button_layout)        # Results text area        self.result_display = QTextEdit()        self.result_display.setReadOnly(True)        self.result_display.setFont(QFont("Arial", self.font_size))        left_layout.addWidget(self.result_display)        # Graphics view for PDF        self.graphics_view = ClickableGraphicsView()        self.graphics_scene = QGraphicsScene()        self.graphics_view.setScene(self.graphics_scene)        layout.addLayout(left_layout, 1)        layout.addWidget(self.graphics_view, 1)        container.setLayout(layout)        self.setCentralWidget(container)        self.status_bar = QStatusBar()        self.setStatusBar(self.status_bar)        # Shortcuts        QShortcut(QKeySequence(Qt.Key_PageUp), self, self.page_up)        QShortcut(QKeySequence(Qt.Key_PageDown), self, self.page_down)        QShortcut(QKeySequence("Ctrl++"), self, self.zoom_in)        QShortcut(QKeySequence("Ctrl+-"), self, self.zoom_out)        QShortcut(QKeySequence("Ctrl+0"), self, self.reset_zoom)        QShortcut(QKeySequence("Alt+Left"), self, self.show_previous_chunk)        QShortcut(QKeySequence("Alt+Right"), self, self.show_next_chunk)        # PDF scrolling shortcuts        QShortcut(QKeySequence("Ctrl+Left"), self, self.scroll_pdf_left)        QShortcut(QKeySequence("Ctrl+Right"), self, self.scroll_pdf_right)        QShortcut(QKeySequence("Ctrl+Up"), self, self.scroll_pdf_up)        QShortcut(QKeySequence("Ctrl+Down"), self, self.scroll_pdf_down)        # Set initial status for Reranking combo        self.update_rerank_combo_status()    def update_rerank_combo_status(self):        current_method = self.search_method_combo.currentText()        if current_method == "BM25":            self.rerank_combo.setEnabled(True)        elif current_method == "Simple text search":            self.rerank_combo.setEnabled(False)        elif current_method == "Embeddings search":            self.rerank_combo.setEnabled(False)        else:            self.rerank_combo.setEnabled(True)    # -------------------------------------------------------------------------    # PDF display and navigation    # -------------------------------------------------------------------------    def display_pdf_page(self, pdf_path, page_number):        try:            doc = fitz.open(pdf_path)            page = doc[page_number - 1]            base_dpi = 150  # base DPI for default zoom            dpi = base_dpi * self.scale_factor            zoom = dpi / 72            mat = fitz.Matrix(zoom, zoom)            pix = page.get_pixmap(matrix=mat)            qt_img = QPixmap()            qt_img.loadFromData(pix.tobytes("ppm"))            self.graphics_scene.clear()            pixmap_item = QGraphicsPixmapItem(qt_img)            self.graphics_scene.addItem(pixmap_item)            word_positions = page.get_text("words")            for word in word_positions:                normalized_word = remove_accents(word[4].lower())                if any(nt == normalized_word for nt in self.query_terms):                    rect = QRectF(word[0] * zoom, word[1] * zoom,                                  (word[2] - word[0]) * zoom, (word[3] - word[1]) * zoom)                    highlight = QGraphicsRectItem(rect)                    highlight.setBrush(QColor(255, 255, 0, 128))                    self.graphics_scene.addItem(highlight)            self.graphics_view.set_pdf_details(pdf_path, page_number, len(doc))            self.graphics_scene.setSceneRect(self.graphics_scene.itemsBoundingRect())        except Exception as e:            self.result_display.setText(f"Error displaying PDF: {e}")    def page_up(self):        if self.graphics_view.current_pdf_path and self.graphics_view.current_page > 1:            self.graphics_view.current_page -= 1            self.display_pdf_page(self.graphics_view.current_pdf_path, self.graphics_view.current_page)    def page_down(self):        if self.graphics_view.current_pdf_path and self.graphics_view.current_page < self.graphics_view.total_pages:            self.graphics_view.current_page += 1            self.display_pdf_page(self.graphics_view.current_pdf_path, self.graphics_view.current_page)    def scroll_pdf_left(self):        hbar = self.graphics_view.horizontalScrollBar()        hbar.setValue(hbar.value() - 50)    def scroll_pdf_right(self):        hbar = self.graphics_view.horizontalScrollBar()        hbar.setValue(hbar.value() + 50)    def scroll_pdf_up(self):        vbar = self.graphics_view.verticalScrollBar()        vbar.setValue(vbar.value() - 50)    def scroll_pdf_down(self):        vbar = self.graphics_view.verticalScrollBar()        vbar.setValue(vbar.value() + 50)    # -------------------------------------------------------------------------    # Searching    # -------------------------------------------------------------------------    def search(self):        global GLOBAL_BM25_MODEL, GLOBAL_CORPUS, GLOBAL_EMBED_MODEL, FASTEMBED_AVAILABLE        query = self.query_input.text().strip()        if not GLOBAL_CORPUS:            self.result_display.setText("No corpus loaded.")            return        if not query:            self.result_display.setText("Please enter a search query.")            return        search_method = self.search_method_combo.currentText()        method = self.rerank_combo.currentText()        # -----------------------------------------------------------------        # CASE 1: "Simple text search"        # -----------------------------------------------------------------        if search_method == "Simple text search":            quoted_phrases, unquoted_words = parse_simple_search_query(query)            quoted_phrases_norm = [remove_accents(p.lower()) for p in quoted_phrases]            unquoted_words_norm = [remove_accents(w.lower()) for w in unquoted_words]            matches = []            for idx, doc in enumerate(GLOBAL_CORPUS):                doc_text_norm = remove_accents(doc['text'].lower()) if 'text' in doc else ""                # Must contain all quoted multi-word substrings                if not all(phrase in doc_text_norm for phrase in quoted_phrases_norm):                    continue                # Must contain all unquoted words                if not all(word in doc_text_norm for word in unquoted_words_norm):                    continue                matches.append(idx)            self.results = [(doc_id, 1.0) for doc_id in matches]            self.current_result_index = 0            if not self.results:                self.result_display.setText("No results found.")            else:                self.show_current_chunk()            self.status_bar.clearMessage()            return        # -----------------------------------------------------------------        # CASE 2: "Embeddings search"        # -----------------------------------------------------------------        if search_method == "Embeddings search":            # We only do this if we actually have embeddings and fastembed installed            if not self.embeddings_present:                self.result_display.setText("No .emb files found. Reverting to BM25 search.")                self.search_method_combo.setCurrentText("BM25")                return            if not FASTEMBED_AVAILABLE or GLOBAL_EMBED_MODEL is None:                self.result_display.setText("FastEmbed library not available. Reverting to BM25 search.")                self.search_method_combo.setCurrentText("BM25")                return            # Proceed with embeddings search:            # 1) Embed the query            query_embedding = list(GLOBAL_EMBED_MODEL.query_embed(query))[0]  # shape (dim,)            # 2) For each doc that has 'embedding', compute dot(embedding, query_embedding)            #    If doc doesn't have 'embedding', skip it            doc_scores = []            for idx, doc in enumerate(GLOBAL_CORPUS):                if 'embedding' not in doc:                    continue                emb = doc['embedding']  # np.array                score = np.dot(emb, query_embedding)                doc_scores.append((idx, float(score)))            # 3) Sort descending            doc_scores.sort(key=lambda x: x[1], reverse=True)            # 4) Truncate or not (your choice). Let's truncate to 50 for consistency            final_ranking = doc_scores[:MAX_SEARCH_RESULTS]            self.results = final_ranking            self.current_result_index = 0            if not self.results:                self.result_display.setText("No results found.")            else:                self.show_current_chunk()            self.status_bar.clearMessage()            return        # -----------------------------------------------------------------        # CASE 3: "BM25"        # -----------------------------------------------------------------        if GLOBAL_BM25_MODEL is None:            self.result_display.setText("No BM25 model is available.")            return        tokenized_query = bm25s.tokenize(query, stopwords="en")        # We'll store self.query_terms for PDF word highlighting        # (split the query by whitespace)        self.query_terms = [remove_accents(term.lower()) for term in query.split()]        results, scores = GLOBAL_BM25_MODEL.retrieve(tokenized_query, k=len(GLOBAL_CORPUS))        bm25_ranking = [(doc_idx, scores[0, i]) for i, doc_idx in enumerate(results[0])]        bm25_ranking.sort(key=lambda x: x[1], reverse=True)        truncated_ranking = bm25_ranking[:MAX_SEARCH_RESULTS]        # Rerank if requested        if method == "No reranking":            final_ranking = truncated_ranking        elif method == "Minimal span-based scoring":            final_ranking = rerank_minimal_span(truncated_ranking, self.query_terms)        elif method == "Exact text search":            final_ranking = rerank_exact_text(truncated_ranking, query)        elif method == "Embeddings rerank":            # This is the rerank with cross-encoder, different from "Embeddings search"            # It uses fastembed.rerank, not the .emb files            if not FASTEMBED_AVAILABLE:                self.result_display.setText("Fastembed not installed. Cannot do embeddings rerank.")                final_ranking = truncated_ranking            else:                # We'll do an old approach as in your original script                final_ranking = self.rerank_with_embeddings(truncated_ranking, query)        else:            final_ranking = truncated_ranking        self.results = final_ranking        self.current_result_index = 0        if not self.results:            self.result_display.setText("No results found.")        else:            self.show_current_chunk()        self.status_bar.clearMessage()    def rerank_with_embeddings(self, top_docs, query_phrase):        """        This uses a cross-encoder approach from fastembed.rerank.cross_encoder,         which is different from "Embeddings search" that uses .emb files.        Original code from your script.         """        # Attempt cross-encoder initialization        from fastembed.rerank.cross_encoder import TextCrossEncoder        encoder = TextCrossEncoder(model_name="Xenova/ms-marco-MiniLM-L-6-v2")        documents = [GLOBAL_CORPUS[doc_id]['text'] for (doc_id, _score) in top_docs]        scores = list(encoder.rerank(query_phrase, documents))        doc_scores = []        for (doc_id, _bm25score), embed_score in zip(top_docs, scores):            doc_scores.append((doc_id, embed_score))        # Sort by descending cross-encoder score        doc_scores.sort(key=lambda x: x[1], reverse=True)        return doc_scores    def show_current_chunk(self):        global GLOBAL_CORPUS        if not self.results:            self.result_display.setText("No results found.")            return        doc_id, score = self.results[self.current_result_index]        chunk_data = GLOBAL_CORPUS[doc_id]        # Let's parse the user's original query for highlighting         # (each word ignoring quotes, punctuation).        raw_query = self.query_input.text()        query_words = re.findall(r"\w+", raw_query, flags=re.IGNORECASE)        self.query_terms = [remove_accents(w.lower()) for w in query_words]        # We'll highlight them in the chunk text (if any).        text_to_display = chunk_data.get('text', "")        highlighted_chunk = self.highlight_query_terms(text_to_display)        self.result_display.setHtml(            f"<b>Result {self.current_result_index + 1} of {len(self.results)}</b><br>"            f"<b>Filename:</b> {chunk_data.get('filename','')}<br>"            f"<b>Page Number:</b> {chunk_data.get('page_number','')}<br>"            f"<b>Score:</b> {score:.4f}<br><br>{highlighted_chunk}"        )        if 'filename' in chunk_data and 'page_number' in chunk_data:            self.display_pdf_page(chunk_data['filename'], chunk_data['page_number'])        else:            self.result_display.append("<br><i>No PDF or page info available.</i>")    def highlight_query_terms(self, text):        normalized_text = remove_accents(text)        highlighted_text = normalized_text        for term in self.query_terms:            escaped_term = re.escape(term)            highlighted_text = re.sub(                rf'(?i)\b({escaped_term})\b',                r'<span style="background-color: yellow;">\1</span>',                highlighted_text,            )        return highlighted_text    # -------------------------------------------------------------------------    # Zoom and font size    # -------------------------------------------------------------------------    def zoom_in(self):        self.scale_factor *= 1.2        self.display_pdf_page(self.graphics_view.current_pdf_path, self.graphics_view.current_page)    def zoom_out(self):        self.scale_factor /= 1.2        self.display_pdf_page(self.graphics_view.current_pdf_path, self.graphics_view.current_page)    def reset_zoom(self):        self.scale_factor = 1.0        self.display_pdf_page(self.graphics_view.current_pdf_path, self.graphics_view.current_page)    def show_next_chunk(self):        if not self.results:            return        self.current_result_index = (self.current_result_index + 1) % len(self.results)        self.show_current_chunk()    def show_previous_chunk(self):        if not self.results:            return        self.current_result_index = (self.current_result_index - 1) % len(self.results)        self.show_current_chunk()    def increase_font_size(self):        self.font_size += 1        self.result_display.setFont(QFont("Arial", self.font_size))        self.query_input.setFont(QFont("Arial", self.font_size))    def decrease_font_size(self):        if self.font_size > 1:            self.font_size -= 1            self.result_display.setFont(QFont("Arial", self.font_size))            self.query_input.setFont(QFont("Arial", self.font_size))################################################################################ Program entry point###############################################################################if __name__ == "__main__":    app = QApplication([])    window = SearchApp()    window.resize(1000, 600)    window.show()    sys.exit(app.exec_())